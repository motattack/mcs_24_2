# –°—É–ø–µ—Ä–∫–æ–º–ø—å—é—Ç–µ—Ä—ã –∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö [üîô](https://github.com/motattack/mcs_24_2)

## ‚ö° CUDA [–ö–ª–∞—Å—Ç–µ—Ä](https://cc.dvfu.ru/)
–ë–∞–∑–æ–≤—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–µ.

### üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥—É–ª—è CUDA:
```shell
module load cuda
```

### üõ†Ô∏è –ö–æ–º–ø–∏–ª—è—Ç–æ—Ä—ã:
```shell
mpic++ –∏–ª–∏ nvcc
```

### üöÄ –ó–∞–ø—É—Å–∫:
```shell
mpiexec -np [—á–∏—Å–ª–æ –ø–æ—Ç–æ–∫–æ–≤]
```

### üìñ –ö–Ω–∏–≥–∏:
1. [CUDA C++ Programming Guide](https://raw.githubusercontent.com/motattack/mcs_24_2/main/spdp/lessons/books/CUDA_guide.pdf)
2. [–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ GPU - –ë–æ—Ä–µ—Å–∫–æ–≤](https://raw.githubusercontent.com/motattack/mcs_24_2/main/spdp/lessons/books/Boreskov_Parallelnye-vychisleniya-na-GPU-Arhitektura-i-programmnaya-model-CUDA.pdf)
3. [CUDA. API - –†–æ–º–∞–Ω–µ–Ω–∫–æ](https://raw.githubusercontent.com/motattack/mcs_24_2/main/spdp/lessons/books/4ICaG_2.pdf)
4. [–û—Å–Ω–æ–≤—ã —Ä–∞–±–æ—Ç—ã —Å —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–µ–π CUDA - –ë–æ—Ä–µ—Å–∫–æ–≤](https://raw.githubusercontent.com/motattack/mcs_24_2/main/spdp/lessons/books/Boreskov_A_V_,_Kharlamov_A_A._Introduction_to_CUDA_Technology_2010.pdf)
5. [–ü—Ä–æ–≥—Ä–∞–º–º–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ CUDA - –ö–∞–ª–≥–∏–Ω](https://raw.githubusercontent.com/motattack/mcs_24_2/main/spdp/lessons/books/cuda-2-program-arch.pdf)
6. [–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è CUDA –≤ –ø—Ä–∏–º–µ—Ä–∞—Ö - –°–∞–Ω–¥–µ—Ä—Å, 2013](https://raw.githubusercontent.com/motattack/mcs_24_2/main/spdp/lessons/books/Sanders_J_,_Kandrot_E._CUDA_by_Example_2013.pdf)
7. [üá¨üáß CUDA Programming - Cook](https://raw.githubusercontent.com/motattack/mcs_24_2/main/spdp/lessons/books/Shane_Cook_‚Äî_CUDA_Programming_A_Developer's_Guide_to_Parallel_Computing.pdf)
8. [üá¨üáß Deep Belief Nets in C++ and CUDA C: Volume 3 - Timothy](https://raw.githubusercontent.com/motattack/mcs_24_2/main/spdp/lessons/books/Masters_T_Deep_Belief_Nets_in_C++_and_CUDA_C_Volume_3_Convolutional.pdf)
9. [üá¨üáß Parallel Computing for Data Science - Norman](https://raw.githubusercontent.com/motattack/mcs_24_2/main/spdp/lessons/books/Norman_Matloff_Parallel_Computing_for_Data_Science_With_Examples.pdf)
10. [üá¨üáß CUDA Application Design and Development - Farber](https://raw.githubusercontent.com/motattack/mcs_24_2/main/spdp/lessons/books/Rob_Farber_‚Äî_CUDA_Application_Design_and_Development_‚Äî_2011.pdf)
11. [üá¨üáß PROFESSIONAL CUDA C Programming - Cheng](https://raw.githubusercontent.com/motattack/mcs_24_2/main/spdp/lessons/books/Cheng_J_,_Grossman_M_,_McKercher_T_Professional_CUDA_C_Programming.pdf)
---


## üìù –ó–∞–¥–∞–Ω–∏–µ 1
–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞—Ç—å –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–¥:
```cu
// —Ñ–∞–π–ª: "hw.cu"
#include <iostream>

int main(int argc, char ** argv) {
  std::cout << "Hello, world!\n";

  return 0;
}
```

–ê —Ç–∞–∫ –∂–µ:
```cu
// —Ñ–∞–π–ª: "hw_d.cu"
#include<iostream>
#include<stdio.h>
#include<cuda_runtime.h>

using namespace std;

__global__ void kernel(void) {
  int ID = blockIdx.x * blockDim.x + threadIdx.x;

  if (ID == 9) {
    printf("blockDim.x %d\n", blockDim.x);
    printf("Hello from block %d, thread %d\n", blockIdx.x, threadIdx.x);
    printf("identificator, or number of thread is %d\n", ID);
  }

  /*	if(ID==10)
  	{	
        printf("Hello from block %d, thread %d\n", blockIdx.x, threadIdx.x);
        printf("Hello from theread %d\n", ID);
      }
  */
}

int main(void) {
  cout << "Hello, CUDA! \n"; //cpu

  kernel << < 2, 10 >>> (); //gpu 

  cudaDeviceSynchronize();

  return 0;
}
```

---

## üìù –ó–∞–¥–∞–Ω–∏–µ 2
–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–ª–æ–∂–µ–Ω–∏–µ –¥–≤—É—Ö –º–∞—Å—Å–∏–≤–æ–≤ –Ω–∞ GPU:

```cu
// Kernel definition
global void VecAdd(float* A, float* B, float* C)
{
    int i = threadIdx.x;
    C[i] = A[i] + B[i];
}
int main()
{
    ...
    // Kernel invocation with N threads
    VecAdd<<<1, N>>>(A, B, C);
    ...
}
```

üìå **–ó–∞–º–µ—á–∞–Ω–∏–µ:**
```cu
int i = blockIdx.x * blockDim.x + threadIdx.x;
```

–°–º. –∫–Ω–∏–≥—É ‚Ññ1. –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π.

---

### üìò –ü—Ä–∏–º–µ—Ä —Ä–µ—à–µ–Ω–∏—è:

```cu
// —Ñ–∞–π–ª: "vecadd_d.cu"
#include <iostream>

#include<stdio.h>

#include <cuda_runtime.h>

#define N 10

__global__ void VecAdd(float * A, float * B, float * C) {
  int i = threadIdx.x;
  C[i] = A[i] + B[i];
}

int main() {
  float * A = new float[N];
  float * B = new float[N];
  float * C = new float[N];

  for (int i = 0; i < N; ++i) {
    A[i] = i;
    B[i] = i * 2.0;
  }

  float * dev_A, * dev_B, * dev_C;
  cudaMalloc((void ** ) & dev_A, sizeof(float) * N);
  cudaMalloc((void ** ) & dev_B, sizeof(float) * N);
  cudaMalloc((void ** ) & dev_C, sizeof(float) * N);

  cudaMemcpy(dev_A, A, sizeof(float) * N, cudaMemcpyHostToDevice);
  cudaMemcpy(dev_B, B, sizeof(float) * N, cudaMemcpyHostToDevice);

  // Kernel invocation with N threads
  VecAdd << < 1, N >>> (dev_A, dev_B, dev_C);

  cudaDeviceSynchronize();

  cudaMemcpy(C, dev_C, sizeof(float) * N, cudaMemcpyDeviceToHost);

  for (int i = 0; i < N; ++i) {
    std::cout << C[i] << "\n";
  }

  delete[] A;
  delete[] B;
  delete[] C;

  cudaFree(dev_A);
  cudaFree(dev_B);
  cudaFree(dev_C);
}
```

---

## üìù –ó–∞–¥–∞–Ω–∏–µ 3
–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–ª–æ–∂–µ–Ω–∏–µ –¥–≤—É—Ö 2-–º–µ—Ä–Ω—ã—Ö –º–∞—Å—Å–∏–≤–æ–≤ –Ω–∞ GPU.

```cu
// Kernel definition
__global__ void MatAdd(float A[N][N], float B[N][N],
                       float C[N][N])
{
    int i = threadIdx.x;
    int j = threadIdx.y;
    C[i][j] = A[i][j] + B[i][j];
}

int main()
{
    ...
    // Kernel invocation with one block of N * N * 1 threads
    int numBlocks = 1;
    dim3 threadsPerBlock(N, N);
    MatAdd<<<numBlocks, threadsPerBlock>>>(A, B, C);
    ...
}

```

–°–º. –∫–Ω–∏–≥—É ‚Ññ1. –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π.

---

## üìù –ó–∞–¥–∞–Ω–∏–µ 4
–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –º–æ–¥–µ—Ä–Ω–∏–∑–æ–≤–∞—Ç—å –∫–æ–¥ –∏–∑ –∑–∞–¥–∞–Ω–∏—è 3,
—á—Ç–æ–±—ã –æ–Ω —Ä–∞–±–æ—Ç–∞–ª –≤ —Å—Ç–∏–ª–µ –≥–µ—Ç–µ—Ä–æ–≥–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è.

–°–º. –∫–Ω–∏–≥—É ‚Ññ1. –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π.

---

## üìù –ó–∞–¥–∞–Ω–∏–µ 5
–ö–æ–¥ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª.
–ó–∞–ø–æ–ª–Ω—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–º–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏ int —á–∏—Å–ª–∞–º–∏
–æ—Ç 0 –¥–æ 10 000 000 –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–π –º–∞—Å—Å–∏–≤ –Ω–∞ GPU.
–í—Ç–æ—Ä–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –Ω–∞–π—Ç–∏ –º–∏–Ω–∏–º—É–º.

---

## üìù –ó–∞–¥–∞–Ω–∏–µ 6
–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫ –º–∏–Ω–∏–º—É–º–∞ —á–µ—Ä–µ–∑ —Ä–∞–∑–¥–µ–ª—è–µ–º—É—é –ø–∞–º—è—Ç—å (__shared__) –≤ –±–ª–æ–∫–µ

---

## üìù –ó–∞–¥–∞–Ω–∏–µ 7
–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫ –º–∏–Ω–∏–º—É–º–∞, –∏—Å–ø–æ–ª—å–∑—É—è –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–µ–¥—É–∫—Ü–∏–∏

---

## üìù –ó–∞–¥–∞–Ω–∏–µ 8 - 3.3.2. –ü—Ä–∏–º–µ—Ä: —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã
–í—ã–ø–æ–ª–Ω–∏—Ç—å —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã

–í –∫–∞—á–µ—Å—Ç–≤–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –∑–∞–¥–∞—á—É —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã $A$ —Ä–∞–∑–º–µ—Ä–∞ $N \times N$.
–î–∞–ª–µ–µ –±—É–¥–µ–º —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ $N$ –∫—Ä–∞—Ç–Ω–æ 16.

–ü–æ—Å–∫–æ–ª—å–∫—É —Å–∞–º–∞ –º–∞—Ç—Ä–∏—Ü–∞ $A$ –¥–≤—É–º–µ—Ä–Ω–∞, —Ç–æ –±—É–¥–µ—Ç —É–¥–æ–±–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–≤—É–º–µ—Ä–Ω—É—é —Å–µ—Ç–∫—É –∏ –¥–≤—É–º–µ—Ä–Ω—ã–µ –±–ª–æ–∫–∏.
–í –∫–∞—á–µ—Å—Ç–≤–µ —Ä–∞–∑–º–µ—Ä–∞ –±–ª–æ–∫–∞ –≤—ã–±–µ—Ä–µ–º $16 \times 16$, —á—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç –∑–∞–ø—É—Å—Ç–∏—Ç—å –¥–æ —Ç—Ä–µ—Ö –±–ª–æ–∫–æ–≤ –Ω–∞ –æ–¥–Ω–æ–º –º—É–ª—å—Ç–∏–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–µ.
–¢–æ–≥–¥–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –º–∞—Ç—Ä–∏—Ü—ã –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ —è–¥—Ä–æ:
```cuda
__global__ void transpose1(float *inData, float *outData, int n) {
    unsigned int xIndex = blockDim.x * blockIdx.x + threadIdx.x;
    unsigned int yIndex = blockDim.y * blockIdx.y + threadIdx.y;
    unsigned int inIndex = xIndex + n * yIndex;
    unsigned int outIndex = yIndex + n * xIndex;

    outData[outIndex] = inData[inIndex];
}
```

---

## üìù –ó–∞–¥–∞–Ω–∏–µ 9 - 3.3.3. –ü—Ä–∏–º–µ—Ä: –ø–µ—Ä–µ–º–Ω–æ–∂–µ–Ω–∏–µ –¥–≤—É—Ö –º–∞—Ç—Ä–∏—Ü
–í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–µ—Ä–µ–º–Ω–æ–∂–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü

–ù–µ—Å–∫–æ–ª—å–∫–æ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–º –ø—Ä–∏–º–µ—Ä–æ–º (–∫ –∫–æ—Ç–æ—Ä–æ–º—É –º—ã —Ç–∞–∫–∂–µ –µ—â–µ –≤–µ—Ä–Ω–µ–º—Å—è –≤ —Å–ª–µ–¥—É—é—â–µ–π –≥–ª–∞–≤–µ)
–±—É–¥–µ—Ç –∑–∞–¥–∞—á–∞ –ø–µ—Ä–µ–º–Ω–æ–∂–µ–Ω–∏—è –¥–≤—É—Ö –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö –º–∞—Ç—Ä–∏—Ü $A$ –∏ $B$
(—Ç–∞–∫–∂–µ –±—É–¥–µ–º —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ –æ–Ω–∏ –æ–±–µ –∏–º–µ—é—Ç —Ä–∞–∑–º–µ—Ä $N \times N$,
–≥–¥–µ $N$ –∫—Ä–∞—Ç–Ω–æ 16). –ü—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ $C$ –¥–≤—É—Ö –º–∞—Ç—Ä–∏—Ü $A$ –∏ $B$ –∑–∞–¥–∞–µ—Ç—Å—è –ø—Ä–∏ –ø–æ–º–æ—â–∏ —Å–ª–µ–¥—É—é—â–µ–π —Ñ–æ—Ä–º—É–ª—ã:

```math
c_{i, j} = \sum_{k=0}^{N-1} a_{i, k} \cdot b_{k, j}.
```

–ö–∞–∫ –∏ –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º –ø—Ä–∏–º–µ—Ä–µ, –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–≤—É–º–µ—Ä–Ω—ã–µ –±–ª–æ–∫–∏ $16 \times 16$ –∏ –¥–≤—É–º–µ—Ä–Ω—É—é —Å–µ—Ç–∫—É. –ù–∏–∂–µ –ø—Ä–∏–≤–æ–¥–∏—Ç—Å—è –ø—Ä–æ—Å—Ç–µ–π—à–∏–π –ø—Ä–∏–º–µ—Ä "–ø–µ—Ä–µ–º–Ω–æ–∂–µ–Ω–∏—è –≤ –ª–æ–±":

```cuda
__global__ void matMult(float *a, float *b, int n, float *c) {
    int bx = blockIdx.x;  // –ò–Ω–¥–µ–∫—Å –±–ª–æ–∫–∞ –ø–æ –æ—Å–∏ X
    int by = blockIdx.y;  // –ò–Ω–¥–µ–∫—Å –±–ª–æ–∫–∞ –ø–æ –æ—Å–∏ Y
    int tx = threadIdx.x; // –ò–Ω–¥–µ–∫—Å –ø–æ—Ç–æ–∫–∞ –≤–Ω—É—Ç—Ä–∏ –±–ª–æ–∫–∞ –ø–æ –æ—Å–∏ X
    int ty = threadIdx.y; // –ò–Ω–¥–µ–∫—Å –ø–æ—Ç–æ–∫–∞ –≤–Ω—É—Ç—Ä–∏ –±–ª–æ–∫–∞ –ø–æ –æ—Å–∏ Y

    float sum = 0.0f; // –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Å—É–º–º—ã

    // –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —ç–ª–µ–º–µ–Ω—Ç–∞ –º–∞—Ç—Ä–∏—Ü—ã A
    int ia = n * BLOCK_SIZE * by + n * ty;

    // –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —ç–ª–µ–º–µ–Ω—Ç–∞ –º–∞—Ç—Ä–∏—Ü—ã B
    int ib = BLOCK_SIZE * bx + tx;

    // –ü–µ—Ä–µ–º–Ω–æ–∂–µ–Ω–∏–µ –∏ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ
    for (int k = 0; k < n; k++) {
        sum += a[ia + k] * b[ib + k * n];
    }

    // –ó–∞–ø–∏—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –º–∞—Ç—Ä–∏—Ü—É C
    int ic = n * BLOCK_SIZE * by + BLOCK_SIZE * bx;
    c[ic + n * ty + tx] = sum;
}
```

---

## üìù –ó–∞–¥–∞–Ω–∏–µ 10 - 3.4.1. –ó–∞–¥–∞—á–∞ –æ–± N-—Ç–µ–ª–∞—Ö
–ß—Ç–æ–±—ã –ø—Ä–æ–∏–ª–ª—é—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è, —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ CUDA —Å–ª–µ–¥—É—é—â–µ–π –∑–∞–¥–∞—á–∏:  
–¥–∞–Ω–æ $N$ —Ç–µ–ª (–¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –∏—Ö –º–∞—Å—Å—ã –æ–¥–∏–Ω–∞–∫–æ–≤—ã) —Å–æ —Å–≤–æ–∏–º–∏ –ø–æ–ª–æ–∂–µ–Ω–∏—è–º–∏ –∏ —Å–∫–æ—Ä–æ—Å—Ç—è–º–∏.  
–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–æ—Å—á–∏—Ç–∞—Ç—å –∏—Ö –¥–≤–∏–∂–µ–Ω–∏–µ –ø–æ–¥ –¥–µ–π—Å—Ç–≤–∏–µ–º —Å–∏–ª –≤–∑–∞–∏–º–Ω–æ–≥–æ –ø—Ä–∏—Ç—è–∂–µ–Ω–∏—è.

–ò–∑ —à–∫–æ–ª—å–Ω–æ–≥–æ –∫—É—Ä—Å–∞ —Ñ–∏–∑–∏–∫–∏ –ø–æ–ª—É—á–∞–µ–º —Ñ–æ—Ä–º—É–ª—É, –æ–ø–∏—Å—ã–≤–∞—é—â—É—é –ø–æ–ª–Ω—É—é —Å–∏–ª—É, –¥–µ–π—Å—Ç–≤—É—é—â—É—é –Ω–∞ $i$-–µ —Ç–µ–ª–æ:  
```math
\mathbf{F}_i = \sum_{j=0}^{N} \frac{C}{\lvert \mathbf{p}_j - \mathbf{p}_i \rvert^3} (\mathbf{p}_j - \mathbf{p}_i),
```

–≥–¥–µ $C$ ‚Äî –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏, –∑–∞–≤–∏—Å—è—â–∞—è –æ—Ç –º–∞—Å—Å –∏ –≥—Ä–∞–≤–∏—Ç–∞—Ü–∏–æ–Ω–Ω–æ–π –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–π,  
–∞ $\mathbf{p}_i$ –∏ $\mathbf{p}_j$ ‚Äî –ø–æ–ª–æ–∂–µ–Ω–∏—è $i$-–≥–æ –∏ $j$-–≥–æ —Ç–µ–ª —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ.

–î–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏—è —Ç–µ–ª –Ω–∞–º –ø–æ–Ω–∞–¥–æ–±—è—Ç—Å—è —á–µ—Ç—ã—Ä–µ –º–∞—Å—Å–∏–≤–∞:  
–ø–æ–ª–æ–∂–µ–Ω–∏—è –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ –≤ —Ç–µ–∫—É—â–∏–π –∏ –≤ —Å–ª–µ–¥—É—é—â–∏–π –º–æ–º–µ–Ω—Ç—ã –≤—Ä–µ–º–µ–Ω–∏.  
–ü–æ—Å–∫–æ–ª—å–∫—É –º—ã –∏–º–µ–µ–º –¥–µ–ª–æ —Å —Ç—Ä–µ—Ö–º–µ—Ä–Ω—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏, —Ç–æ –ø—Ä–æ—â–µ –≤—Å–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∞—Å—Å–∏–≤—ã —Ç–∏–ø–∞ `float3`.